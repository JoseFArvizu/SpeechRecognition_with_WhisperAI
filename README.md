# ðŸ“¢ Speech Recognition with OpenAI Whisper

This project demonstrates how to perform automatic speech recognition (ASR) using OpenAI's Whisper model. It includes transcription of audio files and evaluation using standard metrics like **WER** (Word Error Rate) and **CER** (Character Error Rate).

## ðŸ”§ Features

- Transcribe audio files (`.wav`) using Whisper
- Compare transcriptions against ground truth
- Evaluate transcription performance using:
  - Word Error Rate (WER)
  - Character Error Rate (CER)

## ðŸ§° Technologies Used

- Python
- [OpenAI Whisper](https://github.com/openai/whisper)
- [jiwer](https://github.com/jitsi/jiwer) (for WER and CER calculations)
- Jupyter Notebook

## ðŸ“‚ File Structure

```
SpeechRecognition_with_WhisperAI/
â”œâ”€â”€ SpeechRecognition_with_WhisperAI.ipynb
â”œâ”€â”€ speech_01.wav
â””â”€â”€ README.md
```

## ðŸ“ˆ Example Output

The notebook uses the Whisper model to transcribe `speech_01.wav` and compares the result with a ground truth transcription to calculate accuracy metrics.
